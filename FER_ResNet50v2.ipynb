{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER-ResNet50v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpavankalyan/FER/blob/main/FER_ResNet50v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QamwN0KY00xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf80b626-a2fb-40f1-c815-a8b5506961e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxfLWEId3vCH"
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/FER/FER.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/data\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foE1wN1IQWo6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0FEVsOPfpL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936f2e66-a2db-452f-ed7a-7b2276c9a84a"
      },
      "source": [
        "image_size=224\n",
        "resnet_model = tf.keras.applications.resnet_v2.ResNet50V2(weights='imagenet', include_top=False,input_shape=(image_size, image_size, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrxrvmffnUY"
      },
      "source": [
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8OzPTtGf6Pa"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the resnet convolutional base model\n",
        "model.add(resnet_model)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(7, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQHXf3WSgBDl"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "image_gen = ImageDataGenerator(rotation_range=30, # rotate the image 30 degrees\n",
        "                               width_shift_range=0.1, # Shift the pic width by a max of 10%\n",
        "                               height_shift_range=0.1, # Shift the pic height by a max of 10%\n",
        "                               rescale=1/255, # Rescale the image by normalzing it.\n",
        "                               shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n",
        "                               zoom_range=0.2, # Zoom in by 20% max\n",
        "                               horizontal_flip=True, # Allo horizontal flipping\n",
        "                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xvhJ1IDgBHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14627d11-b4f3-46f1-fdcd-f3ea8d86db55"
      },
      "source": [
        "# Data Generator for Training data\n",
        "train_generator = image_gen.flow_from_directory('/content/data/images/train/',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=80,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28821 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0MkjprvgBMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d110c0-ea4f-428b-e8a9-e7601a55cbbf"
      },
      "source": [
        "validation_generator = image_gen.flow_from_directory('/content/data/images/validation',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=30,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7066 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUucuEoYgBNn"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=0.0005),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ObtLHNgBRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f12e15-7232-4782-eb92-4169f5385660"
      },
      "source": [
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "360/360 [==============================] - 372s 976ms/step - loss: 3.9564 - acc: 0.2415 - val_loss: 1.6060 - val_acc: 0.3742\n",
            "Epoch 2/30\n",
            "360/360 [==============================] - 347s 963ms/step - loss: 1.6924 - acc: 0.3429 - val_loss: 1.5586 - val_acc: 0.4185\n",
            "Epoch 3/30\n",
            "360/360 [==============================] - 347s 962ms/step - loss: 1.6382 - acc: 0.3676 - val_loss: 1.5417 - val_acc: 0.4249\n",
            "Epoch 4/30\n",
            "360/360 [==============================] - 344s 956ms/step - loss: 1.6083 - acc: 0.3835 - val_loss: 1.5251 - val_acc: 0.4328\n",
            "Epoch 5/30\n",
            "360/360 [==============================] - 345s 959ms/step - loss: 1.5836 - acc: 0.3987 - val_loss: 1.4936 - val_acc: 0.4338\n",
            "Epoch 6/30\n",
            "360/360 [==============================] - 346s 959ms/step - loss: 1.5425 - acc: 0.4076 - val_loss: 1.4896 - val_acc: 0.4408\n",
            "Epoch 7/30\n",
            "360/360 [==============================] - 345s 958ms/step - loss: 1.5330 - acc: 0.4106 - val_loss: 1.4660 - val_acc: 0.4720\n",
            "Epoch 8/30\n",
            "360/360 [==============================] - 342s 949ms/step - loss: 1.5167 - acc: 0.4225 - val_loss: 1.4934 - val_acc: 0.4585\n",
            "Epoch 9/30\n",
            "360/360 [==============================] - 341s 948ms/step - loss: 1.5021 - acc: 0.4283 - val_loss: 1.4451 - val_acc: 0.4674\n",
            "Epoch 10/30\n",
            "360/360 [==============================] - 341s 945ms/step - loss: 1.4954 - acc: 0.4292 - val_loss: 1.4446 - val_acc: 0.4724\n",
            "Epoch 11/30\n",
            "360/360 [==============================] - 340s 945ms/step - loss: 1.5065 - acc: 0.4240 - val_loss: 1.4504 - val_acc: 0.4694\n",
            "Epoch 12/30\n",
            "360/360 [==============================] - 341s 946ms/step - loss: 1.4845 - acc: 0.4321 - val_loss: 1.4587 - val_acc: 0.4568\n",
            "Epoch 13/30\n",
            "360/360 [==============================] - 342s 951ms/step - loss: 1.4760 - acc: 0.4448 - val_loss: 1.4210 - val_acc: 0.4823\n",
            "Epoch 14/30\n",
            "360/360 [==============================] - 340s 945ms/step - loss: 1.4646 - acc: 0.4416 - val_loss: 1.4251 - val_acc: 0.4806\n",
            "Epoch 15/30\n",
            "360/360 [==============================] - 341s 946ms/step - loss: 1.4661 - acc: 0.4428 - val_loss: 1.3895 - val_acc: 0.4867\n",
            "Epoch 16/30\n",
            "360/360 [==============================] - 342s 949ms/step - loss: 1.4519 - acc: 0.4519 - val_loss: 1.4291 - val_acc: 0.4815\n",
            "Epoch 17/30\n",
            "360/360 [==============================] - 341s 947ms/step - loss: 1.4571 - acc: 0.4422 - val_loss: 1.4455 - val_acc: 0.4745\n",
            "Epoch 18/30\n",
            "360/360 [==============================] - 341s 946ms/step - loss: 1.4606 - acc: 0.4413 - val_loss: 1.4225 - val_acc: 0.4799\n",
            "Epoch 19/30\n",
            "360/360 [==============================] - 340s 944ms/step - loss: 1.4509 - acc: 0.4503 - val_loss: 1.4264 - val_acc: 0.4839\n",
            "Epoch 20/30\n",
            "360/360 [==============================] - 339s 941ms/step - loss: 1.4404 - acc: 0.4506 - val_loss: 1.4139 - val_acc: 0.4772\n",
            "Epoch 21/30\n",
            "360/360 [==============================] - 342s 951ms/step - loss: 1.4350 - acc: 0.4560 - val_loss: 1.4240 - val_acc: 0.4843\n",
            "Epoch 22/30\n",
            "360/360 [==============================] - 341s 945ms/step - loss: 1.4265 - acc: 0.4551 - val_loss: 1.4327 - val_acc: 0.4926\n",
            "Epoch 23/30\n",
            "360/360 [==============================] - 339s 941ms/step - loss: 1.4348 - acc: 0.4552 - val_loss: 1.4265 - val_acc: 0.4839\n",
            "Epoch 24/30\n",
            "360/360 [==============================] - 338s 938ms/step - loss: 1.4189 - acc: 0.4649 - val_loss: 1.4085 - val_acc: 0.4820\n",
            "Epoch 25/30\n",
            "360/360 [==============================] - 341s 946ms/step - loss: 1.4307 - acc: 0.4575 - val_loss: 1.4048 - val_acc: 0.4911\n",
            "Epoch 26/30\n",
            "360/360 [==============================] - 340s 944ms/step - loss: 1.4258 - acc: 0.4633 - val_loss: 1.4417 - val_acc: 0.4977\n",
            "Epoch 27/30\n",
            "360/360 [==============================] - 340s 944ms/step - loss: 1.4187 - acc: 0.4597 - val_loss: 1.4342 - val_acc: 0.4833\n",
            "Epoch 28/30\n",
            "360/360 [==============================] - 340s 944ms/step - loss: 1.4254 - acc: 0.4641 - val_loss: 1.3859 - val_acc: 0.5037\n",
            "Epoch 29/30\n",
            "360/360 [==============================] - 341s 947ms/step - loss: 1.4212 - acc: 0.4670 - val_loss: 1.3606 - val_acc: 0.5016\n",
            "Epoch 30/30\n",
            "360/360 [==============================] - 341s 946ms/step - loss: 1.4152 - acc: 0.4632 - val_loss: 1.3960 - val_acc: 0.4887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f022a72b7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfOyMcnjQ6N2",
        "outputId": "5c3693c0-2f5d-4e85-cd1c-a0a159c17d35"
      },
      "source": [
        "model.save('/content/drive/MyDrive/FER')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/FER/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}